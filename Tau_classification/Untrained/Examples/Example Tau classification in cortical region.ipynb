{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example script: training tau classifier for cortical regions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in relevant files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\n",
    "                '/Users/mokur/OneDrive - University of Cambridge/Attachments/Jan2023/Tau_pipeline/Tau_classification/')\n",
    "\n",
    "from base import *\n",
    "from constants import *\n",
    "from tau_classification import * \n",
    "import joblib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Screening classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non_tau    12006\n",
      "Tau         9827\n",
      "Name: Class, dtype: int64\n",
      "(21833, 54)\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/mokur/OneDrive - University of Cambridge/Attachments/Jan2023/Tau_pipeline/Tau_classification/Untrained/Training_data/screening_classifier/\"\n",
    "filename = \"training.txt\"\n",
    "\n",
    "# Create tau database object \n",
    "s_data = TauDataBase(path = path,\n",
    "                     filename = filename) \n",
    "\n",
    "# Prepping data to train screening classifier\n",
    "s_data.classifier1_prep()\n",
    "\n",
    "# Check data\n",
    "print(s_data.c1_data['Class'].value_counts())\n",
    "print(s_data.c1_X_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tau classifier for cortical regions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Others    2913\n",
      "CB         661\n",
      "TA         254\n",
      "NFT        126\n",
      "Name: Class, dtype: int64\n",
      "(3954, 54)\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/mokur/OneDrive - University of Cambridge/Attachments/Jan2023/Tau_pipeline/Tau_classification/Untrained/Training_data/cortical_regions/\"\n",
    "filename = \"training.txt\"\n",
    "\n",
    "# Create tau database object \n",
    "cortical_data = TauDataBase(path = path,\n",
    "                            filename = filename) \n",
    "\n",
    "# Prepping data to train tau classifier for cortical regions\n",
    "cortical_data.classifier2_prep()\n",
    "\n",
    "# Check data\n",
    "print(cortical_data.c2_data['Class'].value_counts())\n",
    "print(cortical_data.c2_X_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising & training the classifiers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Screening classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('normalizer', MinMaxScaler()),\n",
       "                ('selector',\n",
       "                 RFE(estimator=RandomForestClassifier(random_state=42),\n",
       "                     n_features_to_select=46)),\n",
       "                ('clf',\n",
       "                 BalancedRandomForestClassifier(class_weight='balanced',\n",
       "                                                max_features=1,\n",
       "                                                min_samples_leaf=2,\n",
       "                                                n_estimators=600,\n",
       "                                                random_state=42))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "screening_model = ScreeningClassifier(hyperparameters=screening_classifier_hyperparams)\n",
    "screening_model.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training \n",
    "screening_model.train(X=s_data.c1_X_train,\n",
    "                      Y=s_data.c1_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ROI: 0.25 µm per pixel: Hematoxylin: Mean</td>\n",
       "      <td>0.043437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ROI: 0.25 µm per pixel: Hematoxylin: Median</td>\n",
       "      <td>0.041947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ROI: 0.25 µm per pixel: Red: Mean</td>\n",
       "      <td>0.038536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ROI: 0.25 µm per pixel: Red: Max</td>\n",
       "      <td>0.036822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ROI: 0.25 µm per pixel: DAB: Haralick Sum aver...</td>\n",
       "      <td>0.034232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             features  importance\n",
       "33          ROI: 0.25 µm per pixel: Hematoxylin: Mean    0.043437\n",
       "34        ROI: 0.25 µm per pixel: Hematoxylin: Median    0.041947\n",
       "37                  ROI: 0.25 µm per pixel: Red: Mean    0.038536\n",
       "36                   ROI: 0.25 µm per pixel: Red: Max    0.036822\n",
       "19  ROI: 0.25 µm per pixel: DAB: Haralick Sum aver...    0.034232"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "screening_model.f_importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['screening_classifier_updated.sav']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "joblib.dump(screening_model, 'screening_classifier_updated3.sav')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tau classifier for cortical regions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('normalizer', MinMaxScaler()),\n",
       "                ('selector',\n",
       "                 RFE(estimator=RandomForestClassifier(random_state=42),\n",
       "                     n_features_to_select=40)),\n",
       "                ('clf',\n",
       "                 BalancedRandomForestClassifier(class_weight='balanced',\n",
       "                                                max_depth=10, max_features=0.2,\n",
       "                                                max_samples=0.75,\n",
       "                                                n_estimators=800,\n",
       "                                                random_state=42,\n",
       "                                                sampling_strategy='not '\n",
       "                                                                  'majority'))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cortical_model = TauClassifier(hyperparameters=cortical_classifier_hyperparams)\n",
    "cortical_model.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training \n",
    "cortical_model.train(X=cortical_data.c2_X_train,\n",
    "                     Y=cortical_data.c2_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0.20178264912940796,\n",
       "  0.9461222841732907,\n",
       "  0.9392187191317515,\n",
       "  0.9545454545454545),\n",
       " 1: (0.6822153285884559,\n",
       "  0.9098161065987153,\n",
       "  0.9409706959706959,\n",
       "  0.8903846153846153),\n",
       " 2: (0.7611313612515783,\n",
       "  0.9922817367544002,\n",
       "  0.9921489382138381,\n",
       "  0.9924504542672882),\n",
       " 3: (0.5047927492593813,\n",
       "  0.9566895472267282,\n",
       "  0.9541859991859992,\n",
       "  0.960923076923077)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cortical_model.best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Min diameter µm</td>\n",
       "      <td>0.129815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Area µm^2</td>\n",
       "      <td>0.129211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Length µm</td>\n",
       "      <td>0.091414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Max diameter µm</td>\n",
       "      <td>0.067562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ROI: 0.25 µm per pixel: DAB: Median</td>\n",
       "      <td>0.049342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               features  importance\n",
       "4                       Min diameter µm    0.129815\n",
       "0                             Area µm^2    0.129211\n",
       "2                             Length µm    0.091414\n",
       "3                       Max diameter µm    0.067562\n",
       "20  ROI: 0.25 µm per pixel: DAB: Median    0.049342"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cortical_model.f_importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cortical_classifier_updated3.sav']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "joblib.dump(cortical_model, 'cortical_classifier_updated3.sav')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting them together: tau classification pipeline for novel *cortical* slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_path = '/Users/mokur/OneDrive - University of Cambridge/Attachments/Jan2023/Detections/cortical/'\n",
    "novel_filename = 'detections.txt'\n",
    "prediction_path = \"C:\\Users\\mokur\\OneDrive\\Desktop\\Digital_path\\Predictions_cortical_update3\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading in files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in:  62 files\n"
     ]
    }
   ],
   "source": [
    "with open(novel_path + novel_filename) as f:\n",
    "    mylist = f.read().splitlines()\n",
    "\n",
    "print(\"Read in: \", len(mylist), \"files\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tau classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE 703471.svs Detections.txt Number:  1 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 703471.svs Detections.txt\n",
      "Data shape is: (41670, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    34189\n",
      "Tau         7481\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       5192\n",
      "CB           1783\n",
      "Ambiguous     194\n",
      "NFT           186\n",
      "TA            126\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  703471.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 703483.svs Detections.txt Number:  2 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 703483.svs Detections.txt\n",
      "Data shape is: (32686, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Tau        17692\n",
      "Non_tau    14994\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       13065\n",
      "CB            3640\n",
      "Ambiguous      399\n",
      "NFT            337\n",
      "TA             251\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  703483.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 703517.svs Detections.txt Number:  3 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 703517.svs Detections.txt\n",
      "Data shape is: (17444, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    10029\n",
      "Tau         7415\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       6148\n",
      "CB           1021\n",
      "Ambiguous     120\n",
      "TA            108\n",
      "NFT            18\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  703517.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 703518.svs Detections.txt Number:  4 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 703518.svs Detections.txt\n",
      "Data shape is: (32999, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    25429\n",
      "Tau         7570\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       5724\n",
      "CB           1439\n",
      "TA            205\n",
      "Ambiguous     166\n",
      "NFT            36\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  703518.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 703522.svs Detections.txt Number:  5 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 703522.svs Detections.txt\n",
      "Data shape is: (13321, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    12723\n",
      "Tau          598\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       539\n",
      "CB            42\n",
      "Ambiguous     16\n",
      "TA             1\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  703522.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 703523.svs Detections.txt Number:  6 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 703523.svs Detections.txt\n",
      "Data shape is: (5040, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    4504\n",
      "Tau         536\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       441\n",
      "CB            70\n",
      "Ambiguous     11\n",
      "TA            10\n",
      "NFT            4\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  703523.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 721732.svs Detections.txt Number:  7 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 721732.svs Detections.txt\n",
      "Data shape is: (109260, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    72462\n",
      "Tau        36798\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       28252\n",
      "CB            5760\n",
      "TA            1684\n",
      "Ambiguous      758\n",
      "NFT            344\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  721732.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 721854.svs Detections.txt Number:  8 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 721854.svs Detections.txt\n",
      "Data shape is: (65193, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    64371\n",
      "Tau          822\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       563\n",
      "CB           224\n",
      "Ambiguous     22\n",
      "TA             7\n",
      "NFT            6\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  721854.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747310.svs Detections.txt Number:  9 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747310.svs Detections.txt\n",
      "Data shape is: (23361, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    18383\n",
      "Tau         4978\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       3997\n",
      "CB            330\n",
      "Ambiguous     276\n",
      "TA            258\n",
      "NFT           117\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747310.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747318.svs Detections.txt Number:  10 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747318.svs Detections.txt\n",
      "Data shape is: (17948, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    16202\n",
      "Tau         1746\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       1494\n",
      "CB            112\n",
      "TA             80\n",
      "Ambiguous      30\n",
      "NFT            30\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747318.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747325.svs Detections.txt Number:  11 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747325.svs Detections.txt\n",
      "Data shape is: (13403, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    11879\n",
      "Tau         1524\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       1050\n",
      "CB            375\n",
      "NFT            43\n",
      "Ambiguous      38\n",
      "TA             18\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747325.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747326.svs Detections.txt Number:  12 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747326.svs Detections.txt\n",
      "Data shape is: (32140, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Tau        16898\n",
      "Non_tau    15242\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       13668\n",
      "CB            1800\n",
      "Ambiguous      680\n",
      "TA             558\n",
      "NFT            192\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747326.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747327.svs Detections.txt Number:  13 / 62\n",
      "---------------STEP1: Read in data file -------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in data file: 747327.svs Detections.txt\n",
      "Data shape is: (37601, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    25868\n",
      "Tau        11733\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       11090\n",
      "TA             243\n",
      "CB             207\n",
      "NFT             97\n",
      "Ambiguous       96\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747327.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747339.svs Detections.txt Number:  14 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747339.svs Detections.txt\n",
      "Data shape is: (24166, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    23384\n",
      "Tau          782\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       704\n",
      "CB            53\n",
      "Ambiguous     13\n",
      "NFT            9\n",
      "TA             3\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747339.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747361.svs Detections.txt Number:  15 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747361.svs Detections.txt\n",
      "Data shape is: (6893, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    6260\n",
      "Tau         633\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       602\n",
      "CB            18\n",
      "TA             8\n",
      "Ambiguous      5\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747361.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747365.svs Detections.txt Number:  16 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747365.svs Detections.txt\n",
      "Data shape is: (19745, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    19373\n",
      "Tau          372\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       338\n",
      "CB            21\n",
      "Ambiguous      8\n",
      "TA             5\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747365.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747372.svs Detections.txt Number:  17 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747372.svs Detections.txt\n",
      "Data shape is: (21718, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    14489\n",
      "Tau         7229\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       6020\n",
      "CB            633\n",
      "TA            272\n",
      "Ambiguous     258\n",
      "NFT            46\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747372.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747383.svs Detections.txt Number:  18 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747383.svs Detections.txt\n",
      "Data shape is: (80513, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    79355\n",
      "Tau         1158\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       696\n",
      "CB           386\n",
      "Ambiguous     33\n",
      "NFT           30\n",
      "TA            13\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747383.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747385.svs Detections.txt Number:  19 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747385.svs Detections.txt\n",
      "Data shape is: (11332, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    10346\n",
      "Tau          986\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       935\n",
      "CB            27\n",
      "Ambiguous     18\n",
      "TA             5\n",
      "NFT            1\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747385.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747829.svs Detections.txt Number:  20 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747829.svs Detections.txt\n",
      "Data shape is: (2712, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    1529\n",
      "Tau        1183\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       1108\n",
      "CB             25\n",
      "NFT            25\n",
      "Ambiguous      14\n",
      "TA             11\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747829.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747831.svs Detections.txt Number:  21 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747831.svs Detections.txt\n",
      "Data shape is: (10970, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    10455\n",
      "Tau          515\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       452\n",
      "CB            19\n",
      "Ambiguous     17\n",
      "NFT           15\n",
      "TA            12\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747831.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747846.svs Detections.txt Number:  22 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747846.svs Detections.txt\n",
      "Data shape is: (95891, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    92220\n",
      "Tau         3671\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       3185\n",
      "CB            350\n",
      "TA             67\n",
      "Ambiguous      47\n",
      "NFT            22\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747846.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747849.svs Detections.txt Number:  23 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747849.svs Detections.txt\n",
      "Data shape is: (40460, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    22305\n",
      "Tau        18155\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       17556\n",
      "CB             225\n",
      "TA             186\n",
      "Ambiguous      120\n",
      "NFT             68\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747849.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 755554.svs Detections.txt Number:  24 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 755554.svs Detections.txt\n",
      "Data shape is: (99016, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    96325\n",
      "Tau         2690\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       2058\n",
      "CB            460\n",
      "TA             88\n",
      "Ambiguous      73\n",
      "NFT            11\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  755554.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 755565.svs Detections.txt Number:  25 / 62\n",
      "---------------STEP1: Read in data file -------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in data file: 755565.svs Detections.txt\n",
      "Data shape is: (33753, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    25346\n",
      "Tau         8407\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       7076\n",
      "CB            540\n",
      "TA            477\n",
      "NFT           163\n",
      "Ambiguous     151\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  755565.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 755566.svs Detections.txt Number:  26 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 755566.svs Detections.txt\n",
      "Data shape is: (26581, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    14201\n",
      "Tau        12380\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       10607\n",
      "TA             747\n",
      "CB             547\n",
      "NFT            251\n",
      "Ambiguous      228\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  755566.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 755567.svs Detections.txt Number:  27 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 755567.svs Detections.txt\n",
      "Data shape is: (171129, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Tau        131757\n",
      "Non_tau     39372\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       124592\n",
      "TA             3641\n",
      "CB             1994\n",
      "Ambiguous      1274\n",
      "NFT             256\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  755567.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 755568.svs Detections.txt Number:  28 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 755568.svs Detections.txt\n",
      "Data shape is: (24803, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    23632\n",
      "Tau         1171\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       1027\n",
      "CB             60\n",
      "TA             42\n",
      "Ambiguous      31\n",
      "NFT            11\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  755568.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 755569.svs Detections.txt Number:  29 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 755569.svs Detections.txt\n",
      "Data shape is: (35923, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    33241\n",
      "Tau         2682\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       2275\n",
      "CB            205\n",
      "TA             90\n",
      "NFT            58\n",
      "Ambiguous      54\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  755569.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 755886.svs Detections.txt Number:  30 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 755886.svs Detections.txt\n",
      "Data shape is: (12022, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    10093\n",
      "Tau         1929\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       1636\n",
      "CB            172\n",
      "TA             55\n",
      "Ambiguous      36\n",
      "NFT            30\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  755886.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 759692.svs Detections.txt Number:  31 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 759692.svs Detections.txt\n",
      "Data shape is: (5612, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    4468\n",
      "Tau        1144\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       1062\n",
      "CB             45\n",
      "Ambiguous      15\n",
      "TA             12\n",
      "NFT            10\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  759692.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 760041.svs Detections.txt Number:  32 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 760041.svs Detections.txt\n",
      "Data shape is: (34633, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    27671\n",
      "Tau         6962\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       6526\n",
      "CB            178\n",
      "TA            148\n",
      "Ambiguous      73\n",
      "NFT            37\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  760041.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 760042.svs Detections.txt Number:  33 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 760042.svs Detections.txt\n",
      "Data shape is: (39393, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    29767\n",
      "Tau         9626\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       9106\n",
      "CB            196\n",
      "TA            171\n",
      "Ambiguous      86\n",
      "NFT            67\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  760042.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 760043.svs Detections.txt Number:  34 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 760043.svs Detections.txt\n",
      "Data shape is: (107191, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Tau        64950\n",
      "Non_tau    42241\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       62779\n",
      "CB             840\n",
      "TA             802\n",
      "Ambiguous      325\n",
      "NFT            204\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  760043.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 760044.svs Detections.txt Number:  35 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 760044.svs Detections.txt\n",
      "Data shape is: (51115, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    31030\n",
      "Tau        20085\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       19161\n",
      "TA             392\n",
      "CB             314\n",
      "Ambiguous      155\n",
      "NFT             63\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  760044.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 760046.svs Detections.txt Number:  36 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 760046.svs Detections.txt\n",
      "Data shape is: (15751, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    8314\n",
      "Tau        7437\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       7169\n",
      "CB            136\n",
      "Ambiguous      57\n",
      "NFT            45\n",
      "TA             30\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  760046.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 760090.svs Detections.txt Number:  37 / 62\n",
      "---------------STEP1: Read in data file -------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in data file: 760090.svs Detections.txt\n",
      "Data shape is: (9135, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    8680\n",
      "Tau         455\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       360\n",
      "CB            74\n",
      "NFT            9\n",
      "Ambiguous      9\n",
      "TA             3\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  760090.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 760091.svs Detections.txt Number:  38 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 760091.svs Detections.txt\n",
      "Data shape is: (27689, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    25654\n",
      "Tau         2035\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       1444\n",
      "CB            456\n",
      "Ambiguous      62\n",
      "NFT            48\n",
      "TA             25\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  760091.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 760093.svs Detections.txt Number:  39 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 760093.svs Detections.txt\n",
      "Data shape is: (13459, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    11270\n",
      "Tau         2189\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       1611\n",
      "CB            435\n",
      "Ambiguous      53\n",
      "NFT            52\n",
      "TA             38\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  760093.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 760094.svs Detections.txt Number:  40 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 760094.svs Detections.txt\n",
      "Data shape is: (9030, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    7742\n",
      "Tau        1288\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       1051\n",
      "CB            170\n",
      "Ambiguous      36\n",
      "NFT            22\n",
      "TA              9\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  760094.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771742.svs Detections.txt Number:  41 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 771742.svs Detections.txt\n",
      "Data shape is: (62208, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    45474\n",
      "Tau        16726\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       13444\n",
      "CB            2286\n",
      "Ambiguous      413\n",
      "TA             355\n",
      "NFT            228\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771742.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771743.svs Detections.txt Number:  42 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 771743.svs Detections.txt\n",
      "Data shape is: (32439, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Tau        23586\n",
      "Non_tau     8853\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       19609\n",
      "CB            2490\n",
      "NFT            567\n",
      "Ambiguous      467\n",
      "TA             453\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771743.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771748.svs Detections.txt Number:  43 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 771748.svs Detections.txt\n",
      "Data shape is: (104600, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    78510\n",
      "Tau        26090\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       19451\n",
      "CB            4326\n",
      "TA            1210\n",
      "Ambiguous      553\n",
      "NFT            550\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771748.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771759.svs Detections.txt Number:  44 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 771759.svs Detections.txt\n",
      "Data shape is: (181231, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    162446\n",
      "Tau         18784\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       11938\n",
      "CB            5932\n",
      "NFT            398\n",
      "Ambiguous      363\n",
      "TA             153\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771759.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771760.svs Detections.txt Number:  45 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 771760.svs Detections.txt\n",
      "Data shape is: (22693, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    16086\n",
      "Tau         6607\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       4547\n",
      "CB           1442\n",
      "Ambiguous     231\n",
      "NFT           228\n",
      "TA            159\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771760.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771761.svs Detections.txt Number:  46 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 771761.svs Detections.txt\n",
      "Data shape is: (133708, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    129801\n",
      "Tau          3907\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       2400\n",
      "CB           1291\n",
      "NFT           117\n",
      "Ambiguous      73\n",
      "TA             26\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771761.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771771.svs Detections.txt Number:  47 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 771771.svs Detections.txt\n",
      "Data shape is: (42779, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    38093\n",
      "Tau         4686\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       4194\n",
      "CB            249\n",
      "TA            135\n",
      "Ambiguous      74\n",
      "NFT            34\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771771.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771772.svs Detections.txt Number:  48 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 771772.svs Detections.txt\n",
      "Data shape is: (97287, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    64144\n",
      "Tau        33143\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       31040\n",
      "CB             798\n",
      "TA             540\n",
      "Ambiguous      431\n",
      "NFT            334\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771772.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771793.svs Detections.txt Number:  49 / 62\n",
      "---------------STEP1: Read in data file -------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in data file: 771793.svs Detections.txt\n",
      "Data shape is: (9368, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    7736\n",
      "Tau        1632\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       1226\n",
      "CB            236\n",
      "NFT            80\n",
      "TA             46\n",
      "Ambiguous      44\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771793.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771805.svs Detections.txt Number:  50 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 771805.svs Detections.txt\n",
      "Data shape is: (16215, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    13306\n",
      "Tau         2909\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       1930\n",
      "CB            418\n",
      "NFT           414\n",
      "Ambiguous      90\n",
      "TA             57\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771805.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771813.svs Detections.txt Number:  51 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 771813.svs Detections.txt\n",
      "Data shape is: (10765, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    10350\n",
      "Tau          415\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       382\n",
      "CB            23\n",
      "TA             4\n",
      "NFT            3\n",
      "Ambiguous      3\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771813.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771814.svs Detections.txt Number:  52 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 771814.svs Detections.txt\n",
      "Data shape is: (18588, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    16903\n",
      "Tau         1685\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       1450\n",
      "CB            140\n",
      "NFT            46\n",
      "Ambiguous      39\n",
      "TA             10\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771814.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771817.svs Detections.txt Number:  53 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 771817.svs Detections.txt\n",
      "Data shape is: (9277, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    8834\n",
      "Tau         443\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       415\n",
      "CB            20\n",
      "NFT            5\n",
      "Ambiguous      2\n",
      "TA             1\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771817.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771819.svs Detections.txt Number:  54 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 771819.svs Detections.txt\n",
      "Data shape is: (10940, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    10220\n",
      "Tau          720\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       669\n",
      "CB            29\n",
      "Ambiguous      9\n",
      "TA             9\n",
      "NFT            4\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771819.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771821.svs Detections.txt Number:  55 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 771821.svs Detections.txt\n",
      "Data shape is: (5849, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    5359\n",
      "Tau         490\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       389\n",
      "CB            53\n",
      "NFT           34\n",
      "Ambiguous     11\n",
      "TA             3\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771821.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771834.svs Detections.txt Number:  56 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 771834.svs Detections.txt\n",
      "Data shape is: (35958, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    31829\n",
      "Tau         4129\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       3292\n",
      "CB            642\n",
      "TA             78\n",
      "Ambiguous      71\n",
      "NFT            46\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771834.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771839.svs Detections.txt Number:  57 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 771839.svs Detections.txt\n",
      "Data shape is: (12852, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    10873\n",
      "Tau         1979\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       1609\n",
      "CB            222\n",
      "TA             58\n",
      "Ambiguous      49\n",
      "NFT            41\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771839.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771848.svs Detections.txt Number:  58 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 771848.svs Detections.txt\n",
      "Data shape is: (43597, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    26180\n",
      "Tau        17417\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       13640\n",
      "CB            2591\n",
      "TA             425\n",
      "Ambiguous      390\n",
      "NFT            371\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771848.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771861.svs Detections.txt Number:  59 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 771861.svs Detections.txt\n",
      "Data shape is: (11832, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Tau        9961\n",
      "Non_tau    1871\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       8740\n",
      "CB            622\n",
      "TA            303\n",
      "Ambiguous     166\n",
      "NFT           130\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771861.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771862.svs Detections.txt Number:  60 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 771862.svs Detections.txt\n",
      "Data shape is: (62208, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Tau        56724\n",
      "Non_tau     5484\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       49553\n",
      "TA            2926\n",
      "CB            2850\n",
      "Ambiguous      964\n",
      "NFT            431\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771862.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771864.svs Detections.txt Number:  61 / 62\n",
      "---------------STEP1: Read in data file -------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in data file: 771864.svs Detections.txt\n",
      "Data shape is: (15061, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    9136\n",
      "Tau        5925\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       4890\n",
      "CB            660\n",
      "TA            162\n",
      "Ambiguous     145\n",
      "NFT            68\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771864.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 772701.svs Detections.txt Number:  62 / 62\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 772701.svs Detections.txt\n",
      "Data shape is: (16038, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    14268\n",
      "Tau         1770\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       1579\n",
      "CB            100\n",
      "NFT            35\n",
      "Ambiguous      33\n",
      "TA             23\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  772701.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "Well done, no error!\n"
     ]
    }
   ],
   "source": [
    "n_total = len(mylist)\n",
    "faulty_file = []\n",
    "for i in range(0, n_total):\n",
    "\n",
    "    # Read in novel slide\n",
    "    print(\"FILE\", mylist[i], \"Number: \", i + 1, \"/\", n_total)\n",
    "    print(\"---------------STEP1: Read in data file -------------------\")\n",
    "    dat_file = mylist[i]\n",
    "\n",
    "    dat_ = pd.read_csv(novel_path + dat_file, sep=\"\\t\")\n",
    "\n",
    "    # Fixing order of the columns\n",
    "    ordered = dat_[extracted_features]\n",
    "\n",
    "    # Changing column names\n",
    "    # since these names tend to be inconsistent causing problems\n",
    "    ordered.columns.values[5] = \"Centroid_X\"\n",
    "    ordered.columns.values[6] = \"Centroid_Y\"\n",
    "\n",
    "    dat = ordered[ordered[\"Class\"] == \"Unlabelled\"]  # only unlabelled cells\n",
    "    print(\"Read in data file:\", dat_file)\n",
    "    print(\"Data shape is:\", dat.shape)\n",
    "\n",
    "    # Classifier 1: separating Non-tau from Tau\n",
    "    print(\n",
    "        \"---------------STEP2: Separating Non-tau from Tau -------------------\"\n",
    "    )\n",
    "    # 1) Remove NA cells\n",
    "    dat = dat.dropna()\n",
    "\n",
    "    predicted1_slide = dat.copy()\n",
    "\n",
    "    # 2) Dropping extra info features\n",
    "    X_unlabelled = dat.drop(\n",
    "        columns=[\"Image\",\n",
    "                 \"Name\",\n",
    "                 \"Class\",\n",
    "                 \"Parent\",\n",
    "                 \"ROI\",\n",
    "                 \"Centroid_X\",\n",
    "                 \"Centroid_Y\"]\n",
    "    )\n",
    "    # 3) Predictions\n",
    "    screening_model.predict(X_unlabelled)\n",
    "    predicted1_slide[\"Class\"] = screening_model.prediction\n",
    "    print(predicted1_slide[\"Class\"].value_counts())\n",
    "\n",
    "    # Classifier 2: tau hallmark classification\n",
    "    print(\n",
    "        \"---------------STEP3: Tau hallmark classification -------------------\"\n",
    "    )\n",
    "    # Select out 'tau' portion only (ignoring non-tau & ambiguous cells )\n",
    "    tau_portion = predicted1_slide[predicted1_slide[\"Class\"] == \"Tau\"]\n",
    "    if tau_portion.shape[0] == 0:\n",
    "        print(\"There is no tau on this slide!\")\n",
    "        faulty_file.append(dat[\"Image\"][0] + \" No tau on the slide\")\n",
    "        continue\n",
    "    tau_portion_X = tau_portion.drop(\n",
    "        columns=[\"Image\",\n",
    "                 \"Name\",\n",
    "                 \"Class\",\n",
    "                 \"Parent\",\n",
    "                 \"ROI\",\n",
    "                 \"Centroid_X\",\n",
    "                 \"Centroid_Y\"])\n",
    "    predicted2_slide = tau_portion.copy()\n",
    "    # Separates out detections that are not tau\n",
    "    non_tau_portion = predicted1_slide[predicted1_slide[\"Class\"] != \"Tau\"]\n",
    "\n",
    "    # Make predictions on Tau objects\n",
    "    cortical_model.predict(tau_portion_X)\n",
    "    predicted2_slide[\"Class\"] = cortical_model.prediction\n",
    "    print(predicted2_slide[\"Class\"].value_counts())\n",
    "\n",
    "    # Extracting data out\n",
    "    print(\"---------------STEP4: Data extraction & export -------------------\")\n",
    "\n",
    "    # 1) Combining predicted cells & excluded cells (prior to prediction)\n",
    "    total_pred = pd.concat([non_tau_portion,\n",
    "                            predicted2_slide])\n",
    "    print(\"No loss of cells? \",\n",
    "          predicted1_slide.shape[0] == total_pred.shape[0])\n",
    "\n",
    "    output_visualise = total_pred[[\"Image\",\n",
    "                                   \"Class\",\n",
    "                                   \"Centroid_X\",\n",
    "                                   \"Centroid_Y\",\n",
    "                                   \"Area µm^2\"]]\n",
    "    path_ = (\n",
    "            prediction_path +\n",
    "            output_visualise.iloc[0, 0] +\n",
    "            \"_predictions.txt\"\n",
    "            )\n",
    "    output_visualise.to_csv(path_, sep=\"\\t\", index=False)\n",
    "\n",
    "    print(\"Exported prediction of : \", dat_file)\n",
    "    print(\"---------------------------------------------------\")\n",
    "print(\"Well done, no error!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "f49f039f1826f29992caaab1300810c8c9e5d31d3955aed133543fc6668591e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
