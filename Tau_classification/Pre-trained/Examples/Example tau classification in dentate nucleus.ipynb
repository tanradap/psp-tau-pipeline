{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example script: extracting tau classifier for dentate nucleus regions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in relevant files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\n",
    "                '/Users/mokur/OneDrive - University of Cambridge/Attachments/Jan2023/Tau_pipeline/Tau_classification/')\n",
    "\n",
    "from base import *\n",
    "from constants import *\n",
    "from tau_classification import *\n",
    "import joblib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Screening classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/mokur/OneDrive - University of Cambridge/Attachments/Jan2023/Tau_pipeline/Tau_classification/Pre-trained/Models/\"\n",
    "filename = \"screening_classifier_updated3.sav\"\n",
    "screening_model = joblib.load(path+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('normalizer', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 RFE(estimator=RandomForestClassifier(random_state=42),\n",
      "                     n_features_to_select=46)),\n",
      "                ('clf',\n",
      "                 BalancedRandomForestClassifier(class_weight='balanced',\n",
      "                                                max_features=1,\n",
      "                                                min_samples_leaf=2,\n",
      "                                                n_estimators=600,\n",
      "                                                random_state=42))])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ROI: 0.25 µm per pixel: Hematoxylin: Mean</td>\n",
       "      <td>0.043437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ROI: 0.25 µm per pixel: Hematoxylin: Median</td>\n",
       "      <td>0.041947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ROI: 0.25 µm per pixel: Red: Mean</td>\n",
       "      <td>0.038536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ROI: 0.25 µm per pixel: Red: Max</td>\n",
       "      <td>0.036822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ROI: 0.25 µm per pixel: DAB: Haralick Sum aver...</td>\n",
       "      <td>0.034232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             features  importance\n",
       "33          ROI: 0.25 µm per pixel: Hematoxylin: Mean    0.043437\n",
       "34        ROI: 0.25 µm per pixel: Hematoxylin: Median    0.041947\n",
       "37                  ROI: 0.25 µm per pixel: Red: Mean    0.038536\n",
       "36                   ROI: 0.25 µm per pixel: Red: Max    0.036822\n",
       "19  ROI: 0.25 µm per pixel: DAB: Haralick Sum aver...    0.034232"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some checks\n",
    "print(screening_model.pipeline)\n",
    "screening_model.f_importance.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tau classifier for dentate nucleus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"/Users/mokur/OneDrive - University of Cambridge/Attachments/Jan2023/Tau_pipeline/Tau_classification/Pre-trained/Models/\"\n",
    "filename = \"dn_classifier.sav\"\n",
    "dn_model = joblib.load(path+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('normalizer', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 RFE(estimator=RandomForestClassifier(random_state=42),\n",
      "                     n_features_to_select=34)),\n",
      "                ('clf',\n",
      "                 BalancedRandomForestClassifier(class_weight='balanced',\n",
      "                                                max_features=0.2,\n",
      "                                                random_state=42,\n",
      "                                                sampling_strategy='not '\n",
      "                                                                  'majority'))])\n",
      "{0: (0.409, 0.9144010858386309, 0.9031204850361197, 0.9314285714285713), 1: (0.422, 0.9811932262266609, 0.9714598662207358, 0.9916666666666668), 2: (0.6599999999999999, 0.9944717736676886, 0.9934360958126922, 0.9955770411295273)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Area µm^2</td>\n",
       "      <td>0.216869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Min diameter µm</td>\n",
       "      <td>0.207962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Max diameter µm</td>\n",
       "      <td>0.058139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Length µm</td>\n",
       "      <td>0.056409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ROI: 0.25 µm per pixel: DAB: Haralick Sum entr...</td>\n",
       "      <td>0.040231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             features  importance\n",
       "0                                           Area µm^2    0.216869\n",
       "4                                     Min diameter µm    0.207962\n",
       "3                                     Max diameter µm    0.058139\n",
       "2                                           Length µm    0.056409\n",
       "19  ROI: 0.25 µm per pixel: DAB: Haralick Sum entr...    0.040231"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dn_model.pipeline)\n",
    "print(dn_model.best_parameters)\n",
    "dn_model.f_importance.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting them together: tau classification pipeline for novel *dentate nucleus* slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_path = '/Users/mokur/OneDrive - University of Cambridge/Attachments/Jan2023/Detections/DN/'\n",
    "novel_filename = 'detections.txt'\n",
    "prediction_path = \"C:/Users/mokur/OneDrive/Desktop/Digital_path/Predictions/DN/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading in files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in:  32 files\n"
     ]
    }
   ],
   "source": [
    "with open(novel_path + novel_filename) as f:\n",
    "    mylist = f.read().splitlines()\n",
    "\n",
    "print(\"Read in: \", len(mylist), \"files\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tau classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE 703480.svs Detections.txt Number:  1 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 703480.svs Detections.txt\n",
      "Data shape is: (2808, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    2787\n",
      "Tau          21\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others    20\n",
      "NFT        1\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  703480.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 703491.svs Detections.txt Number:  2 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 703491.svs Detections.txt\n",
      "Data shape is: (16744, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    11186\n",
      "Tau         5558\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       5105\n",
      "CB            313\n",
      "NFT            83\n",
      "Ambiguous      57\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  703491.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 703529.svs Detections.txt Number:  3 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 703529.svs Detections.txt\n",
      "Data shape is: (11177, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    7222\n",
      "Tau        3955\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       3743\n",
      "CB            144\n",
      "NFT            41\n",
      "Ambiguous      27\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  703529.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 721711.svs Detections.txt Number:  4 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 721711.svs Detections.txt\n",
      "Data shape is: (10690, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    7336\n",
      "Tau        3354\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       3072\n",
      "CB            154\n",
      "NFT            98\n",
      "Ambiguous      30\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  721711.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 721795.svs Detections.txt Number:  5 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 721795.svs Detections.txt\n",
      "Data shape is: (6006, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Tau        3733\n",
      "Non_tau    2273\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       3377\n",
      "CB            223\n",
      "NFT            84\n",
      "Ambiguous      49\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  721795.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 721869.svs Detections.txt Number:  6 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 721869.svs Detections.txt\n",
      "Data shape is: (26090, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    21484\n",
      "Tau         4606\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       4288\n",
      "CB            151\n",
      "NFT           136\n",
      "Ambiguous      31\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  721869.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747282.svs Detections.txt Number:  7 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747282.svs Detections.txt\n",
      "Data shape is: (3882, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    2220\n",
      "Tau        1662\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       1405\n",
      "CB            196\n",
      "NFT            31\n",
      "Ambiguous      30\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747282.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747332.svs Detections.txt Number:  8 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747332.svs Detections.txt\n",
      "Data shape is: (6726, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    3566\n",
      "Tau        3160\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       2809\n",
      "CB            246\n",
      "Ambiguous      60\n",
      "NFT            45\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747332.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747334.svs Detections.txt Number:  9 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747334.svs Detections.txt\n",
      "Data shape is: (15718, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Tau        11194\n",
      "Non_tau     4524\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       10834\n",
      "CB             251\n",
      "NFT             70\n",
      "Ambiguous       39\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747334.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747335.svs Detections.txt Number:  10 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747335.svs Detections.txt\n",
      "Data shape is: (10563, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Tau        5912\n",
      "Non_tau    4651\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       5586\n",
      "CB            179\n",
      "NFT           104\n",
      "Ambiguous      43\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747335.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747337.svs Detections.txt Number:  11 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747337.svs Detections.txt\n",
      "Data shape is: (10926, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Tau        7413\n",
      "Non_tau    3513\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       7114\n",
      "NFT           148\n",
      "CB            119\n",
      "Ambiguous      32\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747337.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747342.svs Detections.txt Number:  12 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747342.svs Detections.txt\n",
      "Data shape is: (9784, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    5968\n",
      "Tau        3816\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       3433\n",
      "CB            251\n",
      "NFT            80\n",
      "Ambiguous      52\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747342.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747344.svs Detections.txt Number:  13 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747344.svs Detections.txt\n",
      "Data shape is: (20672, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Tau        11059\n",
      "Non_tau     9613\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       10263\n",
      "CB             556\n",
      "NFT            150\n",
      "Ambiguous       90\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747344.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747345.svs Detections.txt Number:  14 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747345.svs Detections.txt\n",
      "Data shape is: (2593, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Tau        1614\n",
      "Non_tau     979\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       1475\n",
      "CB            104\n",
      "NFT            18\n",
      "Ambiguous      17\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747345.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747348.svs Detections.txt Number:  15 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747348.svs Detections.txt\n",
      "Data shape is: (5848, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    5015\n",
      "Tau         833\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       751\n",
      "CB            49\n",
      "NFT           21\n",
      "Ambiguous     12\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747348.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747350.svs Detections.txt Number:  16 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747350.svs Detections.txt\n",
      "Data shape is: (12075, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    11011\n",
      "Tau         1064\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       909\n",
      "CB            98\n",
      "NFT           38\n",
      "Ambiguous     19\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747350.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747352.svs Detections.txt Number:  17 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747352.svs Detections.txt\n",
      "Data shape is: (16732, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    11193\n",
      "Tau         5539\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       5006\n",
      "CB            384\n",
      "NFT            95\n",
      "Ambiguous      54\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747352.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747355.svs Detections.txt Number:  18 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747355.svs Detections.txt\n",
      "Data shape is: (19239, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    14639\n",
      "Tau         4600\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       4231\n",
      "CB            238\n",
      "NFT            83\n",
      "Ambiguous      48\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747355.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747356.svs Detections.txt Number:  19 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747356.svs Detections.txt\n",
      "Data shape is: (11382, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    9559\n",
      "Tau        1823\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       1676\n",
      "CB            120\n",
      "Ambiguous      20\n",
      "NFT             7\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747356.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747357.svs Detections.txt Number:  20 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747357.svs Detections.txt\n",
      "Data shape is: (21260, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    20478\n",
      "Tau          782\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       737\n",
      "CB            24\n",
      "NFT           15\n",
      "Ambiguous      6\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747357.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747358.svs Detections.txt Number:  21 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747358.svs Detections.txt\n",
      "Data shape is: (1498, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Tau        1121\n",
      "Non_tau     377\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       1036\n",
      "CB             75\n",
      "NFT             7\n",
      "Ambiguous       3\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747358.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747836.svs Detections.txt Number:  22 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747836.svs Detections.txt\n",
      "Data shape is: (4006, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Tau        3710\n",
      "Non_tau     296\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       3475\n",
      "CB            104\n",
      "NFT            96\n",
      "Ambiguous      35\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747836.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747839.svs Detections.txt Number:  23 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747839.svs Detections.txt\n",
      "Data shape is: (19737, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    17539\n",
      "Tau         2198\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       1839\n",
      "CB            262\n",
      "NFT            50\n",
      "Ambiguous      47\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747839.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747840.svs Detections.txt Number:  24 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747840.svs Detections.txt\n",
      "Data shape is: (20864, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    15085\n",
      "Tau         5779\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       5504\n",
      "CB            188\n",
      "NFT            50\n",
      "Ambiguous      37\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747840.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747843.svs Detections.txt Number:  25 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747843.svs Detections.txt\n",
      "Data shape is: (18075, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    14426\n",
      "Tau         3649\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       3259\n",
      "CB            264\n",
      "NFT            65\n",
      "Ambiguous      61\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747843.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747845.svs Detections.txt Number:  26 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747845.svs Detections.txt\n",
      "Data shape is: (510, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    343\n",
      "Tau        167\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       161\n",
      "NFT            3\n",
      "CB             2\n",
      "Ambiguous      1\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747845.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747852.svs Detections.txt Number:  27 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747852.svs Detections.txt\n",
      "Data shape is: (24286, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    22531\n",
      "Tau         1755\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       1562\n",
      "CB            130\n",
      "NFT            37\n",
      "Ambiguous      26\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747852.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747873.svs Detections.txt Number:  28 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747873.svs Detections.txt\n",
      "Data shape is: (20882, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    12804\n",
      "Tau         8078\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       7397\n",
      "CB            512\n",
      "NFT            90\n",
      "Ambiguous      79\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747873.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 747875.svs Detections.txt Number:  29 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 747875.svs Detections.txt\n",
      "Data shape is: (14169, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    13531\n",
      "Tau          638\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       604\n",
      "CB            19\n",
      "NFT            8\n",
      "Ambiguous      7\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  747875.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771779.svs Detections.txt Number:  30 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 771779.svs Detections.txt\n",
      "Data shape is: (13776, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    10102\n",
      "Tau         3674\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       3428\n",
      "CB            153\n",
      "NFT            68\n",
      "Ambiguous      25\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771779.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 771913.svs Detections.txt Number:  31 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 771913.svs Detections.txt\n",
      "Data shape is: (31204, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    26586\n",
      "Tau         4618\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       4208\n",
      "CB            286\n",
      "Ambiguous      67\n",
      "NFT            57\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  771913.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "FILE 772023.svs Detections.txt Number:  32 / 32\n",
      "---------------STEP1: Read in data file -------------------\n",
      "Read in data file: 772023.svs Detections.txt\n",
      "Data shape is: (7477, 61)\n",
      "---------------STEP2: Separating Non-tau from Tau -------------------\n",
      "Non_tau    5930\n",
      "Tau        1547\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP3: Tau hallmark classification -------------------\n",
      "Others       1470\n",
      "CB             40\n",
      "NFT            30\n",
      "Ambiguous       7\n",
      "Name: Class, dtype: int64\n",
      "---------------STEP4: Data extraction & export -------------------\n",
      "No loss of cells?  True\n",
      "Exported prediction of :  772023.svs Detections.txt\n",
      "---------------------------------------------------\n",
      "Well done, no error!\n"
     ]
    }
   ],
   "source": [
    "n_total = len(mylist)\n",
    "faulty_file = []\n",
    "for i in range(0, n_total):\n",
    "\n",
    "    # Read in novel slide\n",
    "    print(\"FILE\", mylist[i], \"Number: \", i + 1, \"/\", n_total)\n",
    "    print(\"---------------STEP1: Read in data file -------------------\")\n",
    "    dat_file = mylist[i]\n",
    "\n",
    "    dat_ = pd.read_csv(novel_path + dat_file, sep=\"\\t\")\n",
    "\n",
    "    # Fixing order of the columns\n",
    "    ordered = dat_[extracted_features]\n",
    "\n",
    "    # Changing column names\n",
    "    # since these names tend to be inconsistent causing problems\n",
    "    ordered.columns.values[5] = \"Centroid_X\"\n",
    "    ordered.columns.values[6] = \"Centroid_Y\"\n",
    "\n",
    "    dat = ordered[ordered[\"Class\"] == \"Unlabelled\"]  # only unlabelled cells\n",
    "    print(\"Read in data file:\", dat_file)\n",
    "    print(\"Data shape is:\", dat.shape)\n",
    "\n",
    "    # Classifier 1: separating Non-tau from Tau\n",
    "    print(\n",
    "        \"---------------STEP2: Separating Non-tau from Tau -------------------\"\n",
    "    )\n",
    "    # 1) Remove NA cells\n",
    "    dat = dat.dropna()\n",
    "\n",
    "    predicted1_slide = dat.copy()\n",
    "\n",
    "    # 2) Dropping extra info features\n",
    "    X_unlabelled = dat.drop(\n",
    "        columns=[\"Image\",\n",
    "                 \"Name\",\n",
    "                 \"Class\",\n",
    "                 \"Parent\",\n",
    "                 \"ROI\",\n",
    "                 \"Centroid_X\",\n",
    "                 \"Centroid_Y\"]\n",
    "    )\n",
    "    # 3) Predictions\n",
    "    screening_model.predict(X_unlabelled)\n",
    "    predicted1_slide[\"Class\"] = screening_model.prediction\n",
    "    print(predicted1_slide[\"Class\"].value_counts())\n",
    "\n",
    "    # Classifier 2: tau hallmark classification\n",
    "    print(\n",
    "        \"---------------STEP3: Tau hallmark classification -------------------\"\n",
    "    )\n",
    "    # Select out 'tau' portion only (ignoring non-tau & ambiguous cells )\n",
    "    tau_portion = predicted1_slide[predicted1_slide[\"Class\"] == \"Tau\"]\n",
    "    if tau_portion.shape[0] == 0:\n",
    "        print(\"There is no tau on this slide!\")\n",
    "        faulty_file.append(dat[\"Image\"][0] + \" No tau on the slide\")\n",
    "        continue\n",
    "    tau_portion_X = tau_portion.drop(\n",
    "        columns=[\"Image\",\n",
    "                 \"Name\",\n",
    "                 \"Class\",\n",
    "                 \"Parent\",\n",
    "                 \"ROI\",\n",
    "                 \"Centroid_X\",\n",
    "                 \"Centroid_Y\"])\n",
    "    predicted2_slide = tau_portion.copy()\n",
    "    # Separates out detections that are not tau\n",
    "    non_tau_portion = predicted1_slide[predicted1_slide[\"Class\"] != \"Tau\"]\n",
    "\n",
    "    # Make predictions on Tau objects\n",
    "    dn_model.predict(tau_portion_X)\n",
    "    predicted2_slide[\"Class\"] = dn_model.prediction\n",
    "    print(predicted2_slide[\"Class\"].value_counts())\n",
    "\n",
    "    # Extracting data out\n",
    "    print(\"---------------STEP4: Data extraction & export -------------------\")\n",
    "\n",
    "    # 1) Combining predicted cells & excluded cells (prior to prediction)\n",
    "    total_pred = pd.concat([non_tau_portion,\n",
    "                            predicted2_slide])\n",
    "    print(\"No loss of cells? \",\n",
    "          predicted1_slide.shape[0] == total_pred.shape[0])\n",
    "\n",
    "    output_visualise = total_pred[[\"Image\",\n",
    "                                   \"Class\",\n",
    "                                   \"Centroid_X\",\n",
    "                                   \"Centroid_Y\",\n",
    "                                   \"Area µm^2\"]]\n",
    "    path_ = (\n",
    "            prediction_path +\n",
    "            output_visualise.iloc[0, 0] +\n",
    "            \"_predictions.txt\"\n",
    "            )\n",
    "    output_visualise.to_csv(path_, sep=\"\\t\", index=False)\n",
    "\n",
    "    print(\"Exported prediction of : \", dat_file)\n",
    "    print(\"---------------------------------------------------\")\n",
    "print(\"Well done, no error!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f49f039f1826f29992caaab1300810c8c9e5d31d3955aed133543fc6668591e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
